from redis import Redis
from supabase._async.client import AsyncClient
from typing import Dict, List, Any, Tuple, Optional
from app.utils.logger import api_logger
import asyncio
import re
import json
import time
import ast

class CodeAnalysisService:
    """í•¨ìˆ˜ ì¤‘ì‹¬ ì½”ë“œ ë¶„ì„ ë° LLM ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    def __init__(self, redis_client: Redis, supabase: AsyncClient):
        self.redis_client = redis_client
        self.supabase = supabase
        self.function_queue = asyncio.Queue()  # í•¨ìˆ˜ë³„ ë¶„ì„ í
    
    async def analyze_code_changes(self, files: List[Dict], owner: str, repo: str, commit_sha: str, user_id: str):
        """ì½”ë“œ ë³€ê²½ ë¶„ì„ ì§„ì…ì  - ë³€ê²½ëœ í•¨ìˆ˜ë§Œ ì²˜ë¦¬"""
        api_logger.info(f"ì»¤ë°‹ {commit_sha[:8]} í•¨ìˆ˜ë³„ ë¶„ì„ ì‹œì‘: {len(files)}ê°œ íŒŒì¼")
        
        # í†µê³„ ì •ë³´
        total_functions_analyzed = 0
        changed_functions = 0
        new_functions = 0
        cached_functions = 0
        
        for file in files:
            filename = file.get('filename', 'unknown')
            
            if "patch" not in file:
                api_logger.info(f"íŒŒì¼ '{filename}': íŒ¨ì¹˜ ì •ë³´ ì—†ìŒ, ê±´ë„ˆëœ€")
                continue
            
            # diffì—ì„œ ë³€ê²½ëœ ë¼ì¸ ì •ë³´ ì¶”ì¶œ
            diff_info = self._extract_detailed_diff(file.get("patch", ""))
            
            if not diff_info:
                api_logger.info(f"íŒŒì¼ '{filename}': ë³€ê²½ ì‚¬í•­ ì—†ìŒ, ê±´ë„ˆëœ€")
                continue
            
            # íŒ¨ì¹˜ì—ì„œ í˜„ì¬ ì½”ë“œ ìƒíƒœ ì¬êµ¬ì„± (ì „ì²´ íŒŒì¼ ë‚´ìš© ëŒ€ì‹ )
            file_content, _ = self._parse_patch_with_context(file["patch"])
            
            # íŒŒì¼ì„ í•¨ìˆ˜ ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ê³  ë³€ê²½ ì—¬ë¶€ íŒë‹¨
            functions = await self._extract_functions_from_file(file_content, filename, diff_info)
            
            # ë³€ê²½ëœ í•¨ìˆ˜ë§Œ í•„í„°ë§
            changed_or_new_functions = []
            for func_info in functions:
                function_cache_key = f"{user_id}:{commit_sha}:{filename}:{func_info['name']}"
                
                # ì´ë¯¸ ë¶„ì„ëœ í•¨ìˆ˜ëŠ” ìŠ¤í‚µ
                if self.redis_client.exists(function_cache_key):
                    cached_functions += 1
                    api_logger.debug(f"í•¨ìˆ˜ '{func_info['name']}': ì´ë¯¸ ë¶„ì„ ì™„ë£Œ, ìŠ¤í‚µ")
                    continue
                
                # ë³€ê²½ì´ ìˆëŠ” í•¨ìˆ˜ë§Œ ì²˜ë¦¬
                if func_info.get('has_changes', False):
                    changed_or_new_functions.append(func_info)
                    if self._is_new_function(user_id, filename, func_info['name']):
                        new_functions += 1
                        api_logger.info(f"í•¨ìˆ˜ '{func_info['name']}': ìƒˆë¡œìš´ í•¨ìˆ˜ ê°ì§€")
                    else:
                        changed_functions += 1
                        api_logger.info(f"í•¨ìˆ˜ '{func_info['name']}': ë³€ê²½ ì‚¬í•­ ê°ì§€")
                else:
                    api_logger.debug(f"í•¨ìˆ˜ '{func_info['name']}': ë³€ê²½ ì—†ìŒ, íì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ")
            
            # ë³€ê²½ëœ í•¨ìˆ˜ë“¤ë§Œ íì— ì¶”ê°€
            for func_info in changed_or_new_functions:
                await self._enqueue_function_analysis(func_info, commit_sha, user_id, owner, repo)
                total_functions_analyzed += 1
            
            if changed_or_new_functions:
                api_logger.info(f"íŒŒì¼ '{filename}': {len(changed_or_new_functions)}ê°œ ë³€ê²½ëœ í•¨ìˆ˜ë§Œ ë¶„ì„ íì— ì¶”ê°€")
            else:
                api_logger.info(f"íŒŒì¼ '{filename}': ë³€ê²½ëœ í•¨ìˆ˜ ì—†ìŒ, ë¶„ì„ ìŠ¤í‚µ")
        
        # ìµœì¢… í†µê³„ ë¡œê·¸
        api_logger.info(f"ì»¤ë°‹ {commit_sha[:8]} ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ: ë³€ê²½ëœ í•¨ìˆ˜ {changed_functions}ê°œ, ìƒˆ í•¨ìˆ˜ {new_functions}ê°œ, ìºì‹œëœ í•¨ìˆ˜ {cached_functions}ê°œ")
    

    def _is_new_function(self, user_id: str, filename: str, func_name: str) -> bool:
        """í•¨ìˆ˜ê°€ ìƒˆë¡œ ì¶”ê°€ëœ ê²ƒì¸ì§€ í™•ì¸ (ì´ì „ ì»¤ë°‹ì— ì¡´ì¬í•˜ì§€ ì•Šì•˜ë˜ í•¨ìˆ˜)"""
        # í•´ë‹¹ í•¨ìˆ˜ì˜ ì´ì „ ì»¤ë°‹ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        pattern = f"{user_id}:*:{filename}:{func_name}"
        
        cursor = 0
        while True:
            cursor, keys = self.redis_client.scan(cursor, match=pattern, count=100)
            if keys:
                return False  # ì´ì „ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìƒˆë¡œìš´ í•¨ìˆ˜ê°€ ì•„ë‹˜
            if cursor == 0:
                break
        
        return True  # ì´ì „ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œìš´ í•¨ìˆ˜
        
    async def _enqueue_function_analysis(self, func_info: Dict, commit_sha: str, user_id: str, 
                                       owner: str, repo: str, priority: bool = False):
        """í•¨ìˆ˜ë³„ ë¶„ì„ ì‘ì—…ì„ íì— ì¶”ê°€ - ìš°ì„ ìˆœìœ„ ì§€ì›"""
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì°¸ì¡° ì •ë³´ ì¶”ì¶œ

        """í•¨ìˆ˜ë³„ ë¶„ì„ ì‘ì—…ì„ íì— ì¶”ê°€"""
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì°¸ì¡° ì •ë³´ ì¶”ì¶œ
        metadata = self._extract_function_metadata(func_info['code'])
        
        analysis_item = {
            'function_info': func_info,
            'commit_sha': commit_sha,
            'user_id': user_id,
            'owner': owner,
            'repo': repo,
            'metadata': metadata,
            'cache_key': f"{user_id}:{commit_sha}:{func_info['filename']}:{func_info['name']}"
        }
        
        await self.function_queue.put(analysis_item)
        api_logger.info(f"í•¨ìˆ˜ '{func_info['name']}' ë¶„ì„ íì— ì¶”ê°€ë¨")
        
    
    async def process_queue(self):
        """í•¨ìˆ˜ë³„ ë¶„ì„ í ì²˜ë¦¬"""
        api_logger.info("í•¨ìˆ˜ë³„ ë¶„ì„ í ì²˜ë¦¬ ì‹œì‘")
        
        while not self.function_queue.empty():
            try:
                item = await self.function_queue.get()
                await self._analyze_function(item)
                self.function_queue.task_done()
            except Exception as e:
                api_logger.error(f"í•¨ìˆ˜ ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        
        api_logger.info("ëª¨ë“  í•¨ìˆ˜ ë¶„ì„ ì™„ë£Œ")
    
    def _extract_detailed_diff(self, patch: str) -> Dict[int, Dict]:
        """diff íŒ¨ì¹˜ì—ì„œ ìƒì„¸ ë³€ê²½ ì •ë³´ ì¶”ì¶œ(ë¼ì¸)"""
        changes = {}
        current_line = 0
        
        lines = patch.splitlines()
        i = 0
        
        while i < len(lines):
            line = lines[i]
            
            # @@ -a,b +c,d @@ í˜•ì‹ í—¤ë” ì°¾ê¸°
            hunk_match = re.match(r'^@@ -\d+(?:,\d+)? \+(\d+)(?:,(\d+))? @@', line)
            if hunk_match:
                current_line = int(hunk_match.group(1))
                i += 1
                continue
            
            # ì‚­ì œëœ ë¼ì¸
            if line.startswith('-') and not line.startswith('---'):
                old_code = line[1:]
                # ë‹¤ìŒ ë¼ì¸ì´ ì¶”ê°€ ë¼ì¸ì¸ì§€ í™•ì¸ (ìˆ˜ì •)
                if i + 1 < len(lines) and lines[i + 1].startswith('+'):
                    new_code = lines[i + 1][1:]
                    changes[current_line] = {
                        "type": "modified",
                        "old": old_code,
                        "new": new_code
                    }
                    i += 2  # ë‘ ë¼ì¸ ëª¨ë‘ ì²˜ë¦¬
                    current_line += 1
                else:
                    changes[current_line] = {
                        "type": "deleted",
                        "old": old_code,
                        "new": ""
                    }
                    i += 1
                continue
            
            # ì¶”ê°€ëœ ë¼ì¸
            elif line.startswith('+') and not line.startswith('+++'):
                changes[current_line] = {
                    "type": "added",
                    "old": "",
                    "new": line[1:]
                }
                current_line += 1
                i += 1
                continue
            
            # ì»¨í…ìŠ¤íŠ¸ ë¼ì¸ (ë³€ê²½ ì—†ìŒ)
            else:
                current_line += 1
                i += 1
        
        return changes
    
    def _parse_patch_with_context(self, patch: str) -> Tuple[str, Dict[int, Dict]]:
        """íŒ¨ì¹˜ì—ì„œ ì½”ë“œì™€ ë³€ê²½ ì •ë³´ ë™ì‹œ ì¶”ì¶œ - ê¸°ì¡´ê³¼ ë™ì¼"""
        diff_info = self._extract_detailed_diff(patch)
        
        # íŒ¨ì¹˜ì—ì„œ ìµœì¢… ì½”ë“œ ìƒíƒœ ì¬êµ¬ì„±
        lines = []
        current_line = 1
        
        for patch_line in patch.splitlines():
            if patch_line.startswith(("diff ", "index ", "--- ", "+++ ", "@@")):
                continue
            
            if patch_line.startswith('-'):
                continue  # ì‚­ì œëœ ë¼ì¸ì€ ì œì™¸
            elif patch_line.startswith('+'):
                lines.append(patch_line[1:])  # ì¶”ê°€ëœ ë¼ì¸
            else:
                lines.append(patch_line)  # ì»¨í…ìŠ¤íŠ¸ ë¼ì¸
        
        return '\n'.join(lines), diff_info
    
    async def _extract_functions_from_file(self, file_content: str, filename: str, diff_info: Dict) -> List[Dict]:
        """íŒŒì¼ì—ì„œ í•¨ìˆ˜/ë©”ì„œë“œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œ"""
        ext = filename.split('.')[-1].lower() if '.' in filename else ''
        
        #pythonì¼ ê²½ìš°, astì‚¬ìš©
        if ext == 'py':
            return await self._extract_python_functions(file_content, filename, diff_info)
        else:
            return await self._extract_generic_functions(file_content, filename, diff_info, ext)
    
    async def _extract_python_functions(self, file_content: str, filename: str, diff_info: Dict) -> List[Dict]:
        """Python íŒŒì¼ì—ì„œ í•¨ìˆ˜/ë©”ì„œë“œ ê°œë³„ ì¶”ì¶œ (AST ì‚¬ìš©)"""
        functions = []
        
        try:
            tree = ast.parse(file_content)
            lines = file_content.splitlines()
            print(lines)
            # ì „ì—­ ì„í¬íŠ¸ ë° ìƒìˆ˜ ìˆ˜ì§‘
            global_code = []
            function_lines = set()
            
            for node in ast.walk(tree):
                # í´ë˜ìŠ¤ ì •ì˜ ì²˜ë¦¬
                if isinstance(node, ast.ClassDef):
                    class_start = node.lineno
                    class_end = getattr(node, 'end_lineno', class_start)
                    
                    # í´ë˜ìŠ¤ ë‚´ ë©”ì„œë“œë“¤ì„ ê°œë³„ í•¨ìˆ˜ë¡œ ì²˜ë¦¬
                    for item in node.body:
                        if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                            method_start = item.lineno
                            method_end = getattr(item, 'end_lineno', method_start)
                            
                            # ë©”ì„œë“œ ì½”ë“œ ì¶”ì¶œ
                            method_code = '\n'.join(lines[method_start-1:method_end])
                            
                            # ë©”ì„œë“œ ê´€ë ¨ ë³€ê²½ ì‚¬í•­ ì°¾ê¸°
                            method_changes = {
                                line_num: change for line_num, change in diff_info.items()
                                if method_start <= line_num <= method_end
                            }
                            
                            function_name = f"{node.name}.{item.name}"  # í´ë˜ìŠ¤.ë©”ì„œë“œ í˜•ì‹
                            
                            functions.append({
                                'name': function_name,
                                'type': 'method',
                                'code': method_code,
                                'start_line': method_start,
                                'end_line': method_end,
                                'filename': filename,
                                'class_name': node.name,
                                'changes': method_changes,
                                'has_changes': bool(method_changes)
                            })
                            
                            # í•¨ìˆ˜ ë¼ì¸ ê¸°ë¡
                            function_lines.update(range(method_start, method_end + 1))
                
                # ë…ë¦½ í•¨ìˆ˜ ì²˜ë¦¬
                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    # í´ë˜ìŠ¤ ë‚´ë¶€ê°€ ì•„ë‹Œ ë…ë¦½ í•¨ìˆ˜ë§Œ
                    parent_classes = [n for n in ast.walk(tree) if isinstance(n, ast.ClassDef)]
                    is_in_class = any(
                        class_node.lineno <= node.lineno <= getattr(class_node, 'end_lineno', class_node.lineno)
                        for class_node in parent_classes
                    )
                    
                    if not is_in_class:
                        func_start = node.lineno
                        func_end = getattr(node, 'end_lineno', func_start)
                        
                        func_code = '\n'.join(lines[func_start-1:func_end])
                        
                        func_changes = {
                            line_num: change for line_num, change in diff_info.items()
                            if func_start <= line_num <= func_end
                        }
                        
                        functions.append({
                            'name': node.name,
                            'type': 'function',
                            'code': func_code,
                            'start_line': func_start,
                            'end_line': func_end,
                            'filename': filename,
                            'changes': func_changes,
                            'has_changes': bool(func_changes)
                        })
                        
                        function_lines.update(range(func_start, func_end + 1))
            
            # ì „ì—­ ì½”ë“œ (ì„í¬íŠ¸, ìƒìˆ˜ ë“±) ì²˜ë¦¬
            global_lines = []
            global_changes = {}
            
            for i, line in enumerate(lines, 1):
                if i not in function_lines:
                    global_lines.append(line)
                    if i in diff_info:
                        global_changes[i] = diff_info[i]
            
            if global_lines or global_changes:
                functions.insert(0, {
                    'name': 'globals_and_imports',
                    'type': 'global',
                    'code': '\n'.join(global_lines),
                    'start_line': 1,
                    'end_line': len(lines),
                    'filename': filename,
                    'changes': global_changes,
                    'has_changes': bool(global_changes)
                })
            print(functions)
            return functions
            
        except SyntaxError as e:
            api_logger.error(f"Python íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì „ì²´ íŒŒì¼ì„ í•˜ë‚˜ì˜ í•¨ìˆ˜ë¡œ ì²˜ë¦¬
            return [{
                'name': 'entire_file',
                'type': 'file',
                'code': file_content,
                'start_line': 1,
                'end_line': len(file_content.splitlines()),
                'filename': filename,
                'changes': diff_info,
                'has_changes': bool(diff_info)
            }]
    
    async def _extract_generic_functions(self, file_content: str, filename: str, diff_info: Dict, ext: str) -> List[Dict]:
        """ì¼ë°˜ ì–¸ì–´ì˜ í•¨ìˆ˜ ì¶”ì¶œ (ì •ê·œì‹ ê¸°ë°˜)"""
        functions = []
        lines = file_content.splitlines()
        
        # ì–¸ì–´ë³„ í•¨ìˆ˜ íŒ¨í„´
        patterns = {
            'js': r'(?:function\s+(\w+)|const\s+(\w+)\s*=.*?function|(\w+)\s*:\s*(?:async\s+)?function)',
            'ts': r'(?:function\s+(\w+)|const\s+(\w+)\s*=.*?function|(\w+)\s*:\s*(?:async\s+)?function)',
            'java': r'(?:public|private|protected)?\s*(?:static\s+)?[\w<>]+\s+(\w+)\s*\(',
            'c': r'[\w\*\s]+\s+(\w+)\s*\([^)]*\)\s*\{',
            'cpp': r'[\w\*\s:]+\s+(\w+)\s*\([^)]*\)\s*\{',
        }
        
        pattern = patterns.get(ext, r'[\w\s]+\s+(\w+)\s*\([^)]*\)\s*\{')
        
        for match in re.finditer(pattern, file_content, re.MULTILINE):
            func_name = next((g for g in match.groups() if g), "unknown")
            func_start_pos = match.start()
            
            # í•¨ìˆ˜ ì‹œì‘ ë¼ì¸ ê³„ì‚°
            func_start_line = file_content[:func_start_pos].count('\n') + 1
            
            # ì¤‘ê´„í˜¸ ë§¤ì¹­ìœ¼ë¡œ í•¨ìˆ˜ ë ì°¾ê¸°
            func_end_line = self._find_function_end(file_content, func_start_pos)
            
            if func_end_line > func_start_line:
                func_code = '\n'.join(lines[func_start_line-1:func_end_line])
                
                func_changes = {
                    line_num: change for line_num, change in diff_info.items()
                    if func_start_line <= line_num <= func_end_line
                }
                
                functions.append({
                    'name': func_name,
                    'type': 'function',
                    'code': func_code,
                    'start_line': func_start_line,
                    'end_line': func_end_line,
                    'filename': filename,
                    'changes': func_changes,
                    'has_changes': bool(func_changes)
                })
        
        # í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ ì „ì²´ íŒŒì¼ì„ í•˜ë‚˜ì˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        if not functions:
            functions.append({
                'name': 'entire_file',
                'type': 'file',
                'code': file_content,
                'start_line': 1,
                'end_line': len(lines),
                'filename': filename,
                'changes': diff_info,
                'has_changes': bool(diff_info)
            })
        
        return functions
    
    def _find_function_end(self, content: str, start_pos: int) -> int:
        """ì¤‘ê´„í˜¸ ë§¤ì¹­ìœ¼ë¡œ í•¨ìˆ˜ ë ìœ„ì¹˜ ì°¾ê¸°"""
        brace_count = 0
        i = start_pos
        found_first_brace = False
        
        while i < len(content):
            char = content[i]
            if char == '{':
                brace_count += 1
                found_first_brace = True
            elif char == '}':
                brace_count -= 1
                if found_first_brace and brace_count == 0:
                    return content[:i+1].count('\n') + 1
            i += 1
        
        return content[:start_pos].count('\n') + 10  # ê¸°ë³¸ê°’
    
    def _extract_function_metadata(self, code: str) -> Dict[str, Any]:
        """í•¨ìˆ˜ ì½”ë“œì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {}
        
        for i, line in enumerate(code.splitlines()[:10]):  # ì²« 10ì¤„ë§Œ ê²€ì‚¬
            line = line.strip()
            if line.startswith('#'):
                # #[ì°¸ì¡°íŒŒì¼.py]{ë¦¬í„´íƒ€ì…}(ìš”êµ¬ì‚¬í•­) í˜•ì‹ íŒŒì‹±
                pattern = r'#\[([^\]]+)\]\{([^}]+)\}\(([^)]+)\)(.*)'
                match = re.match(pattern, line)
                if match:
                    metadata['reference_file'] = match.group(1)
                    metadata['return_type'] = match.group(2)
                    metadata['requirements'] = match.group(3)
                    metadata['custom_prompt'] = match.group(4).strip()
                    break
                
                # ë‹¨ìˆœ ì°¸ì¡° íŒŒì¼ë§Œ ìˆëŠ” ê²½ìš°: #[íŒŒì¼.py]
                ref_match = re.search(r'\[([^\]]+\.py)\]', line)
                if ref_match:
                    metadata['reference_file'] = ref_match.group(1)
        
        return metadata
    
    async def process_queue(self):
        """í•¨ìˆ˜ë³„ ë¶„ì„ í ì²˜ë¦¬"""
        api_logger.info("í•¨ìˆ˜ë³„ ë¶„ì„ í ì²˜ë¦¬ ì‹œì‘")
        
        while not self.function_queue.empty():
            try:
                item = await self.function_queue.get()
                await self._analyze_function(item)
                self.function_queue.task_done()
            except Exception as e:
                api_logger.error(f"í•¨ìˆ˜ ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        
        api_logger.info("ëª¨ë“  í•¨ìˆ˜ ë¶„ì„ ì™„ë£Œ")
    
    async def _analyze_function(self, item: Dict):
        """ê°œë³„ í•¨ìˆ˜ ë¶„ì„ ì²˜ë¦¬ - ìºì‹œ í‚¤ ê°œì„ """
        func_info = item['function_info']
        func_name = func_info['name']
        filename = func_info['filename']
        user_id = item['user_id']
        commit_sha = item['commit_sha']
        cache_key = item['cache_key']
        
        api_logger.info(f"í•¨ìˆ˜ '{func_name}' ë¶„ì„ ì‹œì‘ (ì»¤ë°‹: {commit_sha[:8]})")
        
        # ë¶„ì„ ì‹œì‘ ì „ ë‹¤ì‹œ í•œë²ˆ ìºì‹œ í™•ì¸ (ë™ì‹œì„± ì²˜ë¦¬)
        if self.redis_client.exists(cache_key):
            api_logger.info(f"í•¨ìˆ˜ '{func_name}': ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì´ë¯¸ ë¶„ì„ ì™„ë£Œ, ìŠ¤í‚µ")
            return
        
        # ì´ì „ ì»¤ë°‹ì—ì„œì˜ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ê°œì„ ëœ ë²„ì „)
        previous_summary = await self._get_previous_function_analysis(
            user_id, filename, func_name, commit_sha
        )
        
        # ì°¸ì¡° íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        reference_content = None
        if 'reference_file' in item['metadata']:
            reference_content = await self._fetch_reference_function(
                item['metadata']['reference_file'], 
                item['owner'], 
                item['repo'], 
                commit_sha
            )
        
        # í•¨ìˆ˜ê°€ ê¸¸ë©´ ì²­í¬ë¡œ ë¶„í• 
        chunks = self._split_function_if_needed(func_info['code'])
        
        if len(chunks) == 1:
            # ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬
            summary = await self._call_llm_for_function(
                func_info, 
                chunks[0], 
                item['metadata'], 
                previous_summary, 
                reference_content,
                commit_sha
            )
        else:
            # ë‹¤ì¤‘ ì²­í¬ ì—°ì† ì²˜ë¦¬
            summary = await self._process_multi_chunk_function(
                func_info, 
                chunks, 
                item['metadata'], 
                previous_summary, 
                reference_content,
                commit_sha
            )
        
        # ìƒˆë¡œìš´ Redis í‚¤ êµ¬ì¡°ë¡œ ì €ì¥
        self.redis_client.setex(cache_key, 86400 * 7, summary)  # 7ì¼ ë³´ê´€
        
        # ì´ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë ˆê±°ì‹œ í‚¤ë„ ì„¤ì • (ì„ íƒì )
        legacy_key = f"func:{filename}:{func_name}"
        self.redis_client.setex(legacy_key, 86400 * 7, summary)
        
        # Notion ì—…ë°ì´íŠ¸ëŠ” íŒŒì¼ ë‹¨ìœ„ë¡œ ë³„ë„ ì²˜ë¦¬
        await self._update_notion_if_needed(func_info, summary, user_id, commit_sha)
        
        api_logger.info(f"í•¨ìˆ˜ '{func_name}' ë¶„ì„ ì™„ë£Œ (ì»¤ë°‹: {commit_sha[:8]})")

    async def _get_previous_function_analysis(self, user_id: str, filename: str, 
                                            func_name: str, current_commit: str) -> Optional[str]:
        """ì´ì „ ì»¤ë°‹ì—ì„œì˜ í•¨ìˆ˜ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        
        # 1. ë™ì¼ í•¨ìˆ˜ì˜ ì´ì „ ì»¤ë°‹ ë¶„ì„ ê²°ê³¼ ê²€ìƒ‰
        pattern = f"{user_id}:*:{filename}:{func_name}"
        matching_keys = []
        
        # Redis SCANì„ ì‚¬ìš©í•˜ì—¬ íŒ¨í„´ ë§¤ì¹­ í‚¤ ì¡°íšŒ
        cursor = 0
        while True:
            cursor, keys = self.redis_client.scan(cursor, match=pattern, count=100)
            matching_keys.extend(keys)
            if cursor == 0:
                break
        
        # í˜„ì¬ ì»¤ë°‹ ì œì™¸í•˜ê³  ê°€ì¥ ìµœê·¼ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
        previous_keys = [key for key in matching_keys if current_commit not in key]
        
        if previous_keys:
            # í‚¤ ì´ë¦„ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœê·¼ ê²ƒë¶€í„°)
            previous_keys.sort(reverse=True)
            latest_key = previous_keys[0]
            
            previous_analysis = self.redis_client.get(latest_key)
            if previous_analysis:
                # ì´ì „ ì»¤ë°‹ í•´ì‹œ ì¶”ì¶œ
                previous_commit = latest_key.split(':')[1]
                api_logger.info(f"í•¨ìˆ˜ '{func_name}': ì´ì „ ì»¤ë°‹ {previous_commit[:8]} ë¶„ì„ ê²°ê³¼ í™œìš©")
                return previous_analysis
        
        api_logger.debug(f"í•¨ìˆ˜ '{func_name}': ì´ì „ ë¶„ì„ ê²°ê³¼ ì—†ìŒ, ìƒˆë¡œ ë¶„ì„")
        return None

    def _split_function_if_needed(self, code: str, max_length: int = 2000) -> List[str]:
        """í•¨ìˆ˜ê°€ ë„ˆë¬´ ê¸¸ë©´ ì²­í¬ë¡œ ë¶„í• """
        if len(code) <= max_length:
            return [code]
        
        # ë‹¨ìˆœ ê¸¸ì´ ê¸°ë°˜ ë¶„í•  (ë³µì¡í•œ ì •ê·œì‹ ì œê±°)
        chunks = []
        for i in range(0, len(code), max_length):
            chunks.append(code[i:i + max_length])
        
        return chunks
    
    async def _process_multi_chunk_function(self, func_info: Dict, chunks: List[str], 
                                          metadata: Dict, previous_summary: str, 
                                          reference_content: str, commit_sha: str) -> str:
        """ë‹¤ì¤‘ ì²­í¬ í•¨ìˆ˜ì˜ ì—°ì†ì  ìš”ì•½ ì²˜ë¦¬"""
        current_summary = previous_summary
        
        for i, chunk in enumerate(chunks):
            api_logger.info(f"í•¨ìˆ˜ '{func_info['name']}' ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬")
            
            # ì´ì „ ìš”ì•½ì„ í¬í•¨í•œ LLM í˜¸ì¶œ
            chunk_summary = await self._call_llm_for_function(
                func_info, 
                chunk, 
                metadata, 
                current_summary,  # ì´ì „ ìš”ì•½ í¬í•¨
                reference_content,
                commit_sha,
                chunk_index=i,
                total_chunks=len(chunks)
            )
            
            current_summary = chunk_summary  # ë‹¤ìŒ ì²­í¬ì—ì„œ ì‚¬ìš©í•  ìš”ì•½ ì—…ë°ì´íŠ¸
        
        return current_summary
    
    async def _call_llm_for_function(self, func_info: Dict, code: str, metadata: Dict, 
                                   previous_summary: str = None, reference_content: str = None,
                                   commit_sha: str = None, chunk_index: int = 0, total_chunks: int = 1) -> str:
        """í•¨ìˆ˜ë³„ LLM ë¶„ì„ í˜¸ì¶œ - ì»¤ë°‹ ì •ë³´ í¬í•¨"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt_parts = []
        
        # ì»¤ë°‹ ì •ë³´ ì¶”ê°€
        if commit_sha:
            prompt_parts.append(f"ğŸ” ì»¤ë°‹ {commit_sha[:8]}ì—ì„œ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.")
        
        # ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        if total_chunks > 1:
            prompt_parts.append(f"ë‹¤ìŒì€ '{func_info['name']}' í•¨ìˆ˜ì˜ {chunk_index+1}/{total_chunks} ì²­í¬ì…ë‹ˆë‹¤.")
        else:
            prompt_parts.append(f"ë‹¤ìŒì€ '{func_info['name']}' í•¨ìˆ˜ì˜ ì½”ë“œì…ë‹ˆë‹¤.")
        
        # ì´ì „ ìš”ì•½ì´ ìˆìœ¼ë©´ í¬í•¨
        if previous_summary:
            prompt_parts.append(f"\nğŸ“‹ ì´ì „ ë¶„ì„ ê²°ê³¼:\n{previous_summary}")
            if total_chunks > 1:
                prompt_parts.append("\nìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì½”ë“œ ì²­í¬ë¥¼ ë¶„ì„í•˜ê³  í†µí•©ëœ ìš”ì•½ì„ ì œê³µí•˜ì„¸ìš”.")
            else:
                prompt_parts.append("\nìœ„ ë¶„ì„ì„ ì°¸ê³ í•˜ì—¬ ë³€ê²½ì‚¬í•­ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì—…ë°ì´íŠ¸ëœ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.")
        
        # ì°¸ì¡° íŒŒì¼ ë‚´ìš© í¬í•¨
        if reference_content:
            prompt_parts.append(f"\nğŸ”— ì°¸ì¡° í•¨ìˆ˜ ì½”ë“œ:\n{reference_content}")
        
        # ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸
        if 'custom_prompt' in metadata:
            prompt_parts.append(f"\nğŸ“ ì¶”ê°€ ìš”êµ¬ì‚¬í•­: {metadata['custom_prompt']}")
        
        if 'return_type' in metadata:
            prompt_parts.append(f"\nâ†©ï¸ ì˜ˆìƒ ë°˜í™˜ íƒ€ì…: {metadata['return_type']}")
        
        if 'requirements' in metadata:
            prompt_parts.append(f"\nâš™ï¸ êµ¬í˜„ ìš”êµ¬ì‚¬í•­: {metadata['requirements']}")
        
        # ë³€ê²½ ì‚¬í•­ì´ ìˆìœ¼ë©´ ê°•ì¡°
        if func_info.get('has_changes', False):
            changes_text = []
            for line_num, change in func_info.get('changes', {}).items():
                if change['type'] == 'modified':
                    changes_text.append(f"ë¼ì¸ {line_num}: '{change['old']}' â†’ '{change['new']}'")
                elif change['type'] == 'added':
                    changes_text.append(f"ë¼ì¸ {line_num}: ì¶”ê°€ë¨ - '{change['new']}'")
                elif change['type'] == 'deleted':
                    changes_text.append(f"ë¼ì¸ {line_num}: ì‚­ì œë¨ - '{change['old']}'")
            
            if changes_text:
                prompt_parts.append(f"\nğŸ”¥ ì´ë²ˆ ì»¤ë°‹ ì£¼ìš” ë³€ê²½ì‚¬í•­:\n" + "\n".join(changes_text))
                prompt_parts.append("\níŠ¹íˆ ìœ„ ë³€ê²½ì‚¬í•­ì˜ ëª©ì ê³¼ ì˜í–¥ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.")
        else:
            prompt_parts.append(f"\nâœ… ì´ë²ˆ ì»¤ë°‹ì—ì„œ ì´ í•¨ìˆ˜ëŠ” ë³€ê²½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë¶„ì„í•  ì½”ë“œ
        prompt_parts.append(f"\nğŸ“„ ë¶„ì„í•  ì½”ë“œ:\n```{func_info.get('filename', '').split('.')[-1]}\n{code}\n```")
        
        # ì‘ë‹µ í˜•ì‹ ì§€ì •
        prompt_parts.append("""
ğŸ“Š ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:
1. **ğŸ¯ ê¸°ëŠ¥ ìš”ì•½**: í•¨ìˆ˜ì˜ í•µì‹¬ ëª©ì ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ
2. **âš™ï¸ ì£¼ìš” ë¡œì§**: í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì´ë‚˜ ì²˜ë¦¬ íë¦„
3. **ğŸ”„ ë³€ê²½ ì˜í–¥**: (ë³€ê²½ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°) ë³€ê²½ìœ¼ë¡œ ì¸í•œ ë™ì‘ ë³€í™”
4. **ğŸ”— ì˜ì¡´ì„±**: ì‚¬ìš©í•˜ëŠ” ì™¸ë¶€ í•¨ìˆ˜ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
5. **ğŸ’¡ ê°œì„  ì œì•ˆ**: (í•„ìš”ì‹œ) ì½”ë“œ í’ˆì§ˆ í–¥ìƒ ë°©ì•ˆ
""")
        
        full_prompt = "\n".join(prompt_parts)
        print(full_prompt)
        # TODO: ì‹¤ì œ LLM API í˜¸ì¶œ êµ¬í˜„
        # ì„ì‹œ ì‘ë‹µ - ì»¤ë°‹ ì •ë³´ í¬í•¨
        return f"[LLM ë¶„ì„ ê²°ê³¼ - ì»¤ë°‹ {commit_sha[:8] if commit_sha else 'unknown'}] {func_info['name']} í•¨ìˆ˜: {func_info.get('type', 'function')} íƒ€ì…"
    
    async def _fetch_reference_function(self, reference_file: str, owner: str, repo: str, commit_sha: str) -> str:
        """ì°¸ì¡° íŒŒì¼ì˜ í•¨ìˆ˜ ìš”ì•½ì„ Redisì—ì„œ ì¡°íšŒ"""
        # íŒŒì¼ì—ì„œ íŠ¹ì • í•¨ìˆ˜ê°€ ì§€ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if '#' in reference_file:
            file_path, func_name = reference_file.split('#', 1)
            redis_key = f"func:{file_path}:{func_name}"
        else:
            # íŒŒì¼ ì „ì²´ ì°¸ì¡°ì¸ ê²½ìš° ì£¼ìš” í•¨ìˆ˜ë“¤ ì¡°íšŒ
            redis_key = f"func:{reference_file}:*"
        
        cached_content = self.redis_client.get(redis_key)
        if cached_content:
            return cached_content
        
        # Redisì— ì—†ìœ¼ë©´ íŒŒì¼ ë‚´ìš© ìš”ì²­ (ê¸°ì¡´ ë°©ì‹ í™œìš©)
        return await self._request_reference_file_content(reference_file, owner, repo, commit_sha)
    
    async def _request_reference_file_content(self, reference_file: str, owner: str, repo: str, commit_sha: str) -> str:
        """GitHubì—ì„œ ì°¸ì¡° íŒŒì¼ ë‚´ìš© ìš”ì²­ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
        # ê¸°ì¡´ êµ¬í˜„ê³¼ ë™ì¼í•œ Redis í‚¤-ê°’ ë°©ì‹ ì‚¬ìš©
        request_id = f"ref_{int(time.time())}_{hash(reference_file) % 1000}"
        
        request_data = {
            'path': reference_file,
            'commit_sha': commit_sha,
            'request_id': request_id
        }
        
        request_key = f"ref_request:{owner}:{repo}:{request_id}"
        response_key = f"ref_response:{owner}:{repo}:{request_id}"
        
        self.redis_client.setex(request_key, 300, json.dumps(request_data))
        
        # 5ì´ˆ í´ë§ ëŒ€ê¸°
        for _ in range(10):
            response_str = self.redis_client.get(response_key)
            if response_str:
                response_data = json.loads(response_str)
                if response_data.get('status') == 'success':
                    return response_data.get('content', '')
            await asyncio.sleep(0.5)
        
        return ""
    
    async def _update_notion_if_needed(self, func_info: Dict, summary: str, user_id: str, commit_sha: str):
        """íŒŒì¼ë³„ ì¢…í•© ë¶„ì„ ë° Notion ì—…ë°ì´íŠ¸"""
        filename = func_info['filename']
        
        # 1. íŒŒì¼ì˜ ëª¨ë“  í•¨ìˆ˜ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if await self._is_file_analysis_complete(filename, user_id, commit_sha):
            # 2. íŒŒì¼ë³„ ì¢…í•© ë¶„ì„ ìˆ˜í–‰
            file_summary = await self._generate_file_level_analysis(filename, user_id)
            
            # 3. Notion AI ìš”ì•½ ë¸”ë¡ ì—…ë°ì´íŠ¸
            await self._update_notion_ai_block(filename, file_summary, user_id)
            
            # 4. ì•„í‚¤í…ì²˜ ê°œì„  ì œì•ˆ ìƒì„±
            await self._generate_architecture_suggestions(filename, file_summary, user_id)

    async def _is_file_analysis_complete(self, filename: str, user_id: str, commit_sha: str) -> bool:
        """íŠ¹ì • ì»¤ë°‹ì—ì„œ íŒŒì¼ì˜ ëª¨ë“  í•¨ìˆ˜ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        
        # í•´ë‹¹ ì»¤ë°‹ê³¼ íŒŒì¼ì˜ ëª¨ë“  í•¨ìˆ˜ í‚¤ ì¡°íšŒ
        pattern = f"{user_id}:{commit_sha}:{filename}:*"
        function_keys = []
        
        cursor = 0
        while True:
            cursor, keys = self.redis_client.scan(cursor, match=pattern, count=100)
            function_keys.extend(keys)
            if cursor == 0:
                break
        
        # ë¶„ì„ ëŒ€ê¸° ì¤‘ì¸ í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ íì—ì„œ í™•ì¸
        temp_queue = []
        pending_functions = set()
        
        # íì—ì„œ í•´ë‹¹ íŒŒì¼ì˜ ëŒ€ê¸° ì¤‘ì¸ í•¨ìˆ˜ë“¤ í™•ì¸
        while not self.function_queue.empty():
            item = await self.function_queue.get()
            temp_queue.append(item)
            
            if (item['function_info']['filename'] == filename and 
                item['commit_sha'] == commit_sha and 
                item['user_id'] == user_id):
                pending_functions.add(item['function_info']['name'])
        
        # íì— ë‹¤ì‹œ ë„£ê¸°
        for item in temp_queue:
            await self.function_queue.put(item)
        
        # ëŒ€ê¸° ì¤‘ì¸ í•¨ìˆ˜ê°€ ì—†ê³ , ë¶„ì„ëœ í•¨ìˆ˜ê°€ ìˆìœ¼ë©´ ì™„ë£Œ
        return len(pending_functions) == 0 and len(function_keys) > 0
    
    def _extract_detailed_diff(self, patch: str) -> Dict[int, Dict]:
        """diff íŒ¨ì¹˜ì—ì„œ ìƒì„¸ ë³€ê²½ ì •ë³´ ì¶”ì¶œ(ë¼ì¸) - ê¸°ì¡´ê³¼ ë™ì¼"""
        changes = {}
        current_line = 0
        
        lines = patch.splitlines()
        i = 0
        
        while i < len(lines):
            line = lines[i]
            
            # @@ -a,b +c,d @@ í˜•ì‹ í—¤ë” ì°¾ê¸°
            hunk_match = re.match(r'^@@ -\d+(?:,\d+)? \+(\d+)(?:,(\d+))? @@', line)
            if hunk_match:
                current_line = int(hunk_match.group(1))
                i += 1
                continue
            
            # ì‚­ì œëœ ë¼ì¸
            if line.startswith('-') and not line.startswith('---'):
                old_code = line[1:]
                # ë‹¤ìŒ ë¼ì¸ì´ ì¶”ê°€ ë¼ì¸ì¸ì§€ í™•ì¸ (ìˆ˜ì •)
                if i + 1 < len(lines) and lines[i + 1].startswith('+'):
                    new_code = lines[i + 1][1:]
                    changes[current_line] = {
                        "type": "modified",
                        "old": old_code,
                        "new": new_code
                    }
                    i += 2  # ë‘ ë¼ì¸ ëª¨ë‘ ì²˜ë¦¬
                    current_line += 1
                else:
                    changes[current_line] = {
                        "type": "deleted",
                        "old": old_code,
                        "new": ""
                    }
                    i += 1
                continue
            
            # ì¶”ê°€ëœ ë¼ì¸
            elif line.startswith('+') and not line.startswith('+++'):
                changes[current_line] = {
                    "type": "added",
                    "old": "",
                    "new": line[1:]
                }
                current_line += 1
                i += 1
                continue
            
            # ì»¨í…ìŠ¤íŠ¸ ë¼ì¸ (ë³€ê²½ ì—†ìŒ)
            else:
                current_line += 1
                i += 1
        
        return changes

    async def _generate_file_level_analysis(self, filename: str, user_id: str) -> str:
        """íŒŒì¼ ì „ì²´ íë¦„ ë¶„ì„ ë° ì¢…í•© ìš”ì•½ ìƒì„±"""
        
        # 1. íŒŒì¼ì˜ ëª¨ë“  í•¨ìˆ˜ ìš”ì•½ ìˆ˜ì§‘
        pattern = f"func:{filename}:*"
        function_keys = self.redis_client.keys(pattern)
        
        function_summaries = {}
        for key in function_keys:
            function_name = key.split(":")[-1]  # func:íŒŒì¼:í•¨ìˆ˜ëª… â†’ í•¨ìˆ˜ëª…
            summary = self.redis_client.get(key)
            if summary:
                function_summaries[function_name] = summary
        
        # 2. í•¨ìˆ˜ë“¤ì„ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
        categorized_functions = {
            'global': [],           # ì „ì—­ ì½”ë“œ
            'class_methods': {},    # í´ë˜ìŠ¤ë³„ ë©”ì„œë“œ ê·¸ë£¹
            'functions': [],        # ë…ë¦½ í•¨ìˆ˜
            'helpers': []          # í—¬í¼ í•¨ìˆ˜
        }
        
        for func_name, summary in function_summaries.items():
            if func_name == 'globals_and_imports':
                categorized_functions['global'].append(summary)
            elif '.' in func_name:  # í´ë˜ìŠ¤.ë©”ì„œë“œ í˜•ì‹
                class_name, method_name = func_name.split('.', 1)
                if class_name not in categorized_functions['class_methods']:
                    categorized_functions['class_methods'][class_name] = []
                categorized_functions['class_methods'][class_name].append({
                    'method': method_name,
                    'summary': summary
                })
            elif func_name.startswith('_'):
                categorized_functions['helpers'].append({
                    'function': func_name,
                    'summary': summary
                })
            else:
                categorized_functions['functions'].append({
                    'function': func_name,
                    'summary': summary
                })
        
        # 3. íŒŒì¼ ì „ì²´ ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        analysis_prompt = f"""
    íŒŒì¼ëª…: {filename}

    ë‹¤ìŒì€ ì´ íŒŒì¼ì˜ ëª¨ë“  í•¨ìˆ˜ë³„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. 
    ì „ì²´ì ì¸ ì•„í‚¤í…ì²˜ íë¦„ê³¼ ê°œì„ ë°©ì•ˆì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

    ## ğŸ“‹ í•¨ìˆ˜ë³„ ë¶„ì„ ê²°ê³¼

    ### ğŸŒ ì „ì—­ ì½”ë“œ (ì„í¬íŠ¸/ìƒìˆ˜)
    {categorized_functions['global'][0] if categorized_functions['global'] else 'ì—†ìŒ'}

    """

        # í´ë˜ìŠ¤ë³„ ë©”ì„œë“œ ì¶”ê°€
        for class_name, methods in categorized_functions['class_methods'].items():
            analysis_prompt += f"""
    ### ğŸ—ï¸ {class_name} í´ë˜ìŠ¤
    """
            for method in methods:
                analysis_prompt += f"""
    **{method['method']}():**
    {method['summary']}

    """

        # ë…ë¦½ í•¨ìˆ˜ë“¤ ì¶”ê°€
        if categorized_functions['functions']:
            analysis_prompt += """
    ### âš¡ ë…ë¦½ í•¨ìˆ˜ë“¤
    """
            for func in categorized_functions['functions']:
                analysis_prompt += f"""
    **{func['function']}():**
    {func['summary']}

    """

        # í—¬í¼ í•¨ìˆ˜ë“¤ ì¶”ê°€
        if categorized_functions['helpers']:
            analysis_prompt += """
    ### ğŸ”§ í—¬í¼ í•¨ìˆ˜ë“¤
    """
            for helper in categorized_functions['helpers']:
                analysis_prompt += f"""
    **{helper['function']}():**
    {helper['summary']}

    """

        # ë¶„ì„ ìš”ì²­ ì¶”ê°€
        analysis_prompt += """
    ## ğŸ¯ ì „ì²´ ë¶„ì„ ìš”ì²­

    ë‹¤ìŒ ê´€ì ì—ì„œ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”:

    ### 1. **ğŸ›ï¸ ì•„í‚¤í…ì²˜ ë¶„ì„**
    - ì „ì²´ì ì¸ ì„¤ê³„ íŒ¨í„´ê³¼ êµ¬ì¡°
    - í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„
    - ì±…ì„ ë¶„ë¦¬ê°€ ì˜ ë˜ì–´ìˆëŠ”ì§€

    ### 2. **ğŸ”„ ë°ì´í„° íë¦„ ë¶„ì„**  
    - ì£¼ìš” ë°ì´í„°ê°€ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ëŠ”ì§€
    - í•¨ìˆ˜ë“¤ ê°„ì˜ í˜¸ì¶œ ê´€ê³„ì™€ ì˜ì¡´ì„±
    - ë³‘ëª© êµ¬ê°„ì´ë‚˜ ê°œì„  í¬ì¸íŠ¸

    ### 3. **ğŸš€ ì„±ëŠ¥ ë° í™•ì¥ì„±**
    - ì„±ëŠ¥ìƒ ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ” ë¶€ë¶„
    - í™•ì¥ì„±ì„ ìœ„í•œ ê°œì„  ë°©ì•ˆ
    - ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™” í¬ì¸íŠ¸

    ### 4. **ğŸ›¡ï¸ ì•ˆì •ì„± ë° ì—ëŸ¬ ì²˜ë¦¬**
    - ì˜ˆì™¸ ì²˜ë¦¬ê°€ ì¶©ë¶„í•œì§€
    - ì—£ì§€ ì¼€ì´ìŠ¤ ëŒ€ì‘ ë°©ì•ˆ
    - ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ê°œì„ ì 

    ### 5. **ğŸ“ˆ ì½”ë“œ í’ˆì§ˆ í‰ê°€**
    - ê°€ë…ì„± ë° ìœ ì§€ë³´ìˆ˜ì„±
    - ì¤‘ë³µ ì½”ë“œë‚˜ ë¦¬íŒ©í† ë§ ëŒ€ìƒ
    - í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±

    ### 6. **ğŸ¯ êµ¬ì²´ì  ê°œì„  ì œì•ˆ**
    - ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ì‚¬í•­ (ìƒ/ì¤‘/í•˜)
    - ê° ê°œì„ ì‚¬í•­ì˜ ì˜ˆìƒ íš¨ê³¼
    - êµ¬í˜„ ë‚œì´ë„ ë° ì†Œìš” ì‹œê°„ ì¶”ì •

    **ì‘ë‹µ í˜•ì‹:** ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ì—¬ Notionì—ì„œ ì½ê¸° ì¢‹ê²Œ ì‘ì„±
    """
        print(analysis_prompt)
        # 4. LLM í˜¸ì¶œí•˜ì—¬ ì¢…í•© ë¶„ì„
        file_analysis = await self._call_llm_for_file_analysis(analysis_prompt)
        
        # 5. ë¶„ì„ ê²°ê³¼ë¥¼ Redisì— ìºì‹± (íŒŒì¼ ë‹¨ìœ„)
        file_cache_key = f"file_analysis:{filename}"
        self.redis_client.setex(file_cache_key, 86400 * 3, file_analysis)  # 3ì¼ ë³´ê´€
        
        return file_analysis

    async def _call_llm_for_file_analysis(self, prompt: str) -> str:
        """íŒŒì¼ ì „ì²´ ë¶„ì„ì„ ìœ„í•œ LLM í˜¸ì¶œ"""
        
        # TODO: ì‹¤ì œ LLM API í˜¸ì¶œ
        # response = await openai.ChatCompletion.acreate(
        #     model="gpt-4-turbo",  # ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•´ turbo ëª¨ë¸ ì‚¬ìš©
        #     messages=[
        #         {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…íŠ¸ì…ë‹ˆë‹¤. ì½”ë“œì˜ ì „ì²´ì ì¸ êµ¬ì¡°ì™€ ê°œì„ ë°©ì•ˆì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
        #         {"role": "user", "content": prompt}
        #     ],
        #     temperature=0.3,
        #     max_tokens=2000
        # )
        # return response.choices[0].message.content
        
        # ì„ì‹œ ì‘ë‹µ
        print(prompt)
        return f"""
    # ğŸ“Š {prompt.split('íŒŒì¼ëª…: ')[1].split()[0]} ì „ì²´ ë¶„ì„ ë³´ê³ ì„œ

    ## ğŸ›ï¸ ì•„í‚¤í…ì²˜ ë¶„ì„
    - **ì„¤ê³„ íŒ¨í„´**: ì„œë¹„ìŠ¤ ë ˆì´ì–´ íŒ¨í„´ ì ìš©
    - **êµ¬ì¡°**: ì˜ ëª¨ë“ˆí™”ëœ í´ë˜ìŠ¤ ì¤‘ì‹¬ ì„¤ê³„
    - **ì±…ì„ ë¶„ë¦¬**: ê° í•¨ìˆ˜ê°€ ë‹¨ì¼ ì±…ì„ ì›ì¹™ì„ ì˜ ì¤€ìˆ˜

    ## ğŸ”„ ë°ì´í„° íë¦„ ë¶„ì„
    - **ì£¼ìš” íë¦„**: íŒŒì¼ â†’ í•¨ìˆ˜ ì¶”ì¶œ â†’ ê°œë³„ ë¶„ì„ â†’ í ì²˜ë¦¬
    - **ë³‘ëª© êµ¬ê°„**: LLM API í˜¸ì¶œ ë¶€ë¶„ì—ì„œ ì§€ì—° ê°€ëŠ¥ì„±
    - **ê°œì„  í¬ì¸íŠ¸**: ë³‘ë ¬ ì²˜ë¦¬ ë„ì… ê°€ëŠ¥

    ## ğŸš€ ì„±ëŠ¥ ë° í™•ì¥ì„±
    - **ì„±ëŠ¥**: Redis ìºì‹±ìœ¼ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬
    - **í™•ì¥ì„±**: í ê¸°ë°˜ ì„¤ê³„ë¡œ í™•ì¥ ìš©ì´
    - **ìµœì í™”**: í•¨ìˆ˜ ë¶„í•  ë¡œì§ ê°œì„  ì—¬ì§€

    ## ğŸ›¡ï¸ ì•ˆì •ì„± ë° ì—ëŸ¬ ì²˜ë¦¬
    - **ì˜ˆì™¸ ì²˜ë¦¬**: try-catch ë¸”ë¡ ì¶©ë¶„íˆ í™œìš©
    - **ë¡œê¹…**: ê° ë‹¨ê³„ë³„ ë¡œê¹… ì˜ êµ¬í˜„
    - **ê°œì„ **: íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ì¶”ê°€ í•„ìš”

    ## ğŸ“ˆ ì½”ë“œ í’ˆì§ˆ í‰ê°€
    â­â­â­â­â­ (5/5)
    - **ê°€ë…ì„±**: ë§¤ìš° ìš°ìˆ˜
    - **ìœ ì§€ë³´ìˆ˜ì„±**: ëª¨ë“ˆí™” ì˜ ë¨
    - **í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±**: ê° í•¨ìˆ˜ê°€ ë…ë¦½ì 

    ## ğŸ¯ êµ¬ì²´ì  ê°œì„  ì œì•ˆ

    ### ğŸ”¥ ìƒìˆœìœ„ (ì¦‰ì‹œ ì ìš©)
    1. **LLM API ì‹¤ì œ ì—°ë™** - 2ì‹œê°„ ì†Œìš”
    2. **ë³‘ë ¬ ì²˜ë¦¬ ë„ì…** - 4ì‹œê°„ ì†Œìš”

    ### ğŸš€ ì¤‘ìˆœìœ„ (1ì£¼ ë‚´)
    1. **ì—ëŸ¬ ì¬ì‹œë„ ë¡œì§ ê°•í™”** - 6ì‹œê°„ ì†Œìš”
    2. **ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì¶”ê°€** - 1ì¼ ì†Œìš”

    ### ğŸ’¡ í•˜ìˆœìœ„ (ì¥ê¸°)
    1. **ML ê¸°ë°˜ ì½”ë“œ í’ˆì§ˆ ì˜ˆì¸¡** - 1ì£¼ ì†Œìš”
    2. **ì‹¤ì‹œê°„ í˜‘ì—… ê¸°ëŠ¥** - 2ì£¼ ì†Œìš”
    """
    

    async def _update_notion_ai_block(self, filename: str, file_summary: str, user_id: str):
        """Notion AI ìš”ì•½ ë¸”ë¡ ì—…ë°ì´íŠ¸"""
        
        try:
            # 1. í•´ë‹¹ íŒŒì¼ê³¼ ì—°ê´€ëœ í•™ìŠµ í˜ì´ì§€ ì°¾ê¸°
            # (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ êµ¬í˜„, ì‹¤ì œë¡œëŠ” Supabaseì—ì„œ ì¡°íšŒ)
            
            # 2. AI ìš”ì•½ ë¸”ë¡ ID ì¡°íšŒ
            # ai_block_id = await get_ai_block_id_by_filename(filename, user_id)
            
            # 3. Notion APIë¡œ ë¸”ë¡ ì—…ë°ì´íŠ¸
            # await notion_service.update_ai_summary_by_block(ai_block_id, file_summary)
            
            api_logger.info(f"íŒŒì¼ '{filename}' Notion ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            api_logger.error(f"Notion ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

    async def _generate_architecture_suggestions(self, filename: str, file_summary: str, user_id: str):
        """ì•„í‚¤í…ì²˜ ê°œì„  ì œì•ˆ ìƒì„± ë° ë³„ë„ ì €ì¥"""
        
        # ê°œì„  ì œì•ˆë§Œ ì¶”ì¶œí•˜ëŠ” LLM í˜¸ì¶œ
        suggestions_prompt = f"""
    íŒŒì¼ëª…: {filename}
    ë‹¤ìŒ íŒŒì¼ ë¶„ì„ ê²°ê³¼ì—ì„œ **êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ì œì•ˆ**ë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

    {file_summary}

    í˜•ì‹:
    ## ğŸš€ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥ (1-2ì‹œê°„)
    - [ ] êµ¬ì²´ì  ê°œì„ ì‚¬í•­ 1
    - [ ] êµ¬ì²´ì  ê°œì„ ì‚¬í•­ 2

    ## ğŸ”§ ë‹¨ê¸° ê°œì„  (1ì£¼ ì´ë‚´)  
    - [ ] êµ¬ì²´ì  ê°œì„ ì‚¬í•­ 3
    - [ ] êµ¬ì²´ì  ê°œì„ ì‚¬í•­ 4

    ## ğŸ’¡ ì¥ê¸° ê°œì„  (1ê°œì›” ì´ë‚´)
    - [ ] êµ¬ì²´ì  ê°œì„ ì‚¬í•­ 5
    - [ ] êµ¬ì²´ì  ê°œì„ ì‚¬í•­ 6
    """
        
        suggestions = await self._call_llm_for_file_analysis(suggestions_prompt)
        
        # Redisì— ê°œì„  ì œì•ˆ ë³„ë„ ì €ì¥
        suggestions_key = f"suggestions:{filename}"
        self.redis_client.setex(suggestions_key, 86400 * 7, suggestions)  # 7ì¼ ë³´ê´€
        
        api_logger.info(f"íŒŒì¼ '{filename}' ê°œì„  ì œì•ˆ ìƒì„± ì™„ë£Œ")