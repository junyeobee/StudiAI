import redis
import asyncio
import os
import sys
from typing import Dict, List
from rq import Queue, SimpleWorker, Worker, SpawnWorker, get_current_job
from rq.timeouts import TimerDeathPenalty
from app.services.code_analysis_service import CodeAnalysisService
from app.core.config import settings
from worker.config import RQ_CONFIG
from app.utils.logger import api_logger
from supabase._async.client import create_client as create_async_client

# ë²„í¼ë§ ë¹„í™œì„±í™”
os.environ["PYTHONUNBUFFERED"] = "1"

# ê¸°ë³¸ ëª¨ë“ˆë“¤ import
from worker.config import RQ_CONFIG

# OSë³„ ë¶„ê¸° import
if os.name == 'nt':  # Windows
    from worker.optim_rq_for_win import RQOptimizerForWin as RQOptimizer
    from worker.dead_letter_handle_for_win import handle_failed_job_win as handle_failed_job
    api_logger.info("Windows ì „ìš© RQ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
else:  # Linux/Unix
    from worker.optim_rq import RQOptimizer
    from worker.dead_letter_handle import handle_failed_job
    api_logger.info("Linux/Unix RQ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")

# Windowsìš© ì›Œì»¤ í´ë˜ìŠ¤ë“¤
class WindowsSimpleWorker(SimpleWorker):
    """Windowsì—ì„œ SIGALRM ì‹ í˜¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì›Œì»¤"""
    death_penalty_class = TimerDeathPenalty

class WindowsSpawnWorker(SpawnWorker):
    """Windowsìš© ìµœì í™”ëœ SpawnWorker"""
    death_penalty_class = TimerDeathPenalty

# Redis ì„¤ì •
redis_host = settings.REDIS_HOST
redis_port = int(settings.REDIS_PORT)
redis_password = settings.REDIS_PASSWORD

def create_redis_connection():
    """ì•ˆì •ì ì¸ Redis ì—°ê²° ìƒì„± - íƒ€ì„ì•„ì›ƒ ë° ì¬ì‹œë„ ì„¤ì • í¬í•¨"""
    return redis.Redis(
        host=redis_host,
        port=redis_port,
        password=redis_password,
        socket_timeout=10,  # ì½ê¸° íƒ€ì„ì•„ì›ƒ
        socket_connect_timeout=5,  # ì—°ê²° íƒ€ì„ì•„ì›ƒ
        retry_on_timeout=True,
        health_check_interval=30,
        max_connections=20,  # ì»¤ë„¥ì…˜ í’€ í¬ê¸°
        decode_responses=False  # bytes ì‘ë‹µ ìœ ì§€ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)
    )

# Redis ì—°ê²°
redis_conn = create_redis_connection()

# RQ í ìƒì„± (ì„¤ì • ì ìš©)
task_queue = Queue(
    'code_analysis', 
    connection=redis_conn,
    default_timeout=RQ_CONFIG['worker']['timeout']
)

def analyze_code_task(files: List[Dict], owner: str, repo: str, commit_sha: str, user_id: str):
    """ì½”ë“œ ë¶„ì„ íƒœìŠ¤í¬ - RQ ì›Œì»¤ì—ì„œ ì‹¤í–‰ (OS ë¬´ê´€)"""
    try:
        platform = "Windows" if os.name == 'nt' else "Linux/Unix"
        api_logger.info(f"RQ ì›Œì»¤ì—ì„œ ì½”ë“œ ë¶„ì„ ì‹œì‘ ({platform}): {commit_sha[:8]}, íŒŒì¼ ìˆ˜: {len(files)}")
        api_logger.info(f"ì‚¬ìš©ì ID: {user_id}, ì €ì¥ì†Œ: {owner}/{repo}")

        # ğŸ”§ ì´ë²¤íŠ¸ ë£¨í”„ ì•ˆì „ì„± ê°œì„ : ì¤‘ì²© ë£¨í”„ ë°©ì§€
        loop = None
        try:
            # ê¸°ì¡´ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
            loop = asyncio.get_running_loop()
            api_logger.info("ê¸°ì¡´ ì´ë²¤íŠ¸ ë£¨í”„ ê°ì§€ë¨ - ìƒˆ ë£¨í”„ ìƒì„±")
        except RuntimeError:
            # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìŒ - ì •ìƒ ìƒí™©
            pass
        
        if loop and loop.is_running():
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìƒˆ ë£¨í”„ ìƒì„±
            new_loop = asyncio.new_event_loop()
            asyncio.set_event_loop(new_loop)
            try:
                result = new_loop.run_until_complete(_analyze_code_async(files, owner, repo, commit_sha, user_id))
                return result
            finally:
                new_loop.close()
                # ì›ë˜ ë£¨í”„ ë³µì›
                asyncio.set_event_loop(loop)
        else:
            # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ì§ì ‘ ì‹¤í–‰
            return asyncio.run(_analyze_code_async(files, owner, repo, commit_sha, user_id))

    except Exception as e:
        api_logger.error(f"RQ ì›Œì»¤ ì½”ë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        raise e

async def _analyze_code_async(files: List[Dict], owner: str, repo: str, commit_sha: str, user_id: str):
    """ë¹„ë™ê¸° ì½”ë“œ ë¶„ì„ ì‹¤í–‰"""
    try:
        # ê³µê°œ í™˜ê²½ë³€ìˆ˜ ë…¸ì¶œ ë°©ì§€ - SUPABASE_KEY ë§ˆìŠ¤í‚¹
        masked_key = settings.SUPABASE_KEY[:10] + "..." if settings.SUPABASE_KEY else "None"
        api_logger.info(f"ì½”ë“œ ë¶„ì„ ì‹œì‘ - Supabase URL: {settings.SUPABASE_URL}, Key: {masked_key}")
        
        # Supabase ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        supabase = await create_async_client(settings.SUPABASE_URL, settings.SUPABASE_KEY)
        
        # Redis í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        redis_conn = create_redis_connection()
        
        # CodeAnalysisService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        analysis_service = CodeAnalysisService(redis_conn, supabase)
        
        api_logger.info(f"ë¶„ì„ ëŒ€ìƒ: {len(files)}ê°œ íŒŒì¼, ì»¤ë°‹: {commit_sha[:8]}")
        
        # âœ… ë¡œì»¬ LLM í™˜ê²½ì— ë§ì¶° íƒ€ì„ì•„ì›ƒ ì—°ì¥ (5ë¶„ â†’ 30ë¶„)
        job = get_current_job()
        job.timeout = 1800  # 30ë¶„
        
        # 1. ë³€ê²½ëœ íŒŒì¼ë“¤ì„ í•¨ìˆ˜ ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ê³  íì— ì¶”ê°€
        await analysis_service.analyze_code_changes(files, owner, repo, commit_sha, user_id)
        
        # 2. íì— ìˆëŠ” ëª¨ë“  í•¨ìˆ˜ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¶„ì„
        await analysis_service.process_queue()
        
        api_logger.info("ëª¨ë“  ì½”ë“œ ë¶„ì„ ì™„ë£Œ")
        
    except Exception as e:
        api_logger.error(f"ì½”ë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        api_logger.error(f"ìƒì„¸ ì˜¤ë¥˜ ì •ë³´: {traceback.format_exc()}")
        raise
    finally:
        # âœ… Step 5: ì›Œì»¤ ì¢…ë£Œì‹œ ê³µìœ  ThreadPoolExecutor ì •ë¦¬
        try:
            await CodeAnalysisService.cleanup_executor()
            api_logger.info("ì›Œì»¤ íƒœìŠ¤í¬ ì¢…ë£Œ - ThreadPoolExecutor ì •ë¦¬ ì™„ë£Œ")
        except Exception as cleanup_error:
            api_logger.error(f"ThreadPoolExecutor ì •ë¦¬ ì‹¤íŒ¨: {cleanup_error}")
            api_logger.error(traceback.format_exc())

def create_optimized_worker():
    """OSë³„ ìµœì í™”ëœ ì›Œì»¤ ìƒì„±"""
    worker_config = RQ_CONFIG['worker']
    
    # í”Œë«í¼ë³„ ì›Œì»¤ ìƒì„±
    if os.name == 'nt':  # Windows
        # Windowsì—ì„œëŠ” ë¬´ì¡°ê±´ SimpleWorker ì‚¬ìš© (os.wait4() ì—ëŸ¬ ë°©ì§€)
        worker = WindowsSimpleWorker(
            [task_queue], 
            connection=redis_conn,
            exception_handlers=[handle_failed_job]
        )
        api_logger.info("Windows SimpleWorker ìƒì„± (os.wait4() ì—ëŸ¬ ë°©ì§€)")
            
    else:  # Unix/Linux
        worker = Worker(
            [task_queue], 
            connection=redis_conn,
            exception_handlers=[handle_failed_job]
        )
        api_logger.info("Unix/Linux Worker ìƒì„±")
    
    # ì›Œì»¤ ì„¤ì • ì ìš©
    worker.default_result_ttl = worker_config['result_ttl']
    worker.default_worker_ttl = worker_config['default_worker_ttl']
    
    # Windows íŠ¹í™” ì„¤ì •
    if os.name == 'nt':
        # Windowsì—ì„œ ë” ê¸´ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        worker.job_timeout = worker_config.get('job_timeout', 600) * 1.5
        worker.default_worker_ttl = worker_config.get('default_worker_ttl', 420) * 1.2
    
    return worker

def start_worker():
    """RQ ì›Œì»¤ ì‹œì‘ - OSë³„ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§ í¬í•¨"""
    optimizer = None
    worker = None
    
    try:
        platform = "Windows" if os.name == 'nt' else "Linux/Unix"
        api_logger.info(f"=== RQ ìµœì í™” ì›Œì»¤ ì‹œì‘ ({platform}) ===")
        
        # ì„¤ì • ì •ë³´ ë¡œê¹…
        api_logger.info(f"ì›Œì»¤ ì„¤ì •: {RQ_CONFIG['worker']}")
        api_logger.info(f"ì‹¤íŒ¨ ì²˜ë¦¬ ì„¤ì •: {RQ_CONFIG['failure']}")
        api_logger.info(f"ìŠ¤ì¼€ì¼ë§ ì„¤ì •: {RQ_CONFIG['scaling']}")
        
        # ìµœì í™”ëœ ì›Œì»¤ ìƒì„±
        worker = create_optimized_worker()
        
        # ë™ì  ìŠ¤ì¼€ì¼ë§ ì‹œì‘ (OSë³„ ë¶„ê¸°)
        if os.getenv('ENABLE_AUTO_SCALING', 'true').lower() == 'true':
            optimizer = RQOptimizer(redis_conn)
            optimizer.start_monitoring()
            api_logger.info(f"ë™ì  ìŠ¤ì¼€ì¼ë§ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ({platform})")
        
        # ì›Œì»¤ ì‹œì‘
        api_logger.info(f"ì›Œì»¤ê°€ ì‘ì—…ì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤... ({platform})")
        
        # Windowsì—ì„œëŠ” ë” ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰
        if os.name == 'nt':
            worker.work(
                burst=False,  # ì§€ì†ì  ì‹¤í–‰
                logging_level='INFO',
                with_scheduler=False  # Windowsì—ì„œëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„í™œì„±í™”
            )
        else:
            worker.work(
                burst=False,  # ì§€ì†ì  ì‹¤í–‰
                logging_level='INFO',
                with_scheduler=True   # Linuxì—ì„œëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ í™œì„±í™”
            )
            
    except KeyboardInterrupt:
        api_logger.info("ì›Œì»¤ ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
        
    except Exception as e:
        api_logger.error(f"ì›Œì»¤ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise
        
    finally:
        # ğŸ”§ í™•ì‹¤í•œ ì •ë¦¬ ì‘ì—…
        api_logger.info("ì›Œì»¤ ì •ë¦¬ ì‘ì—… ì‹œì‘")
        
        # ì˜µí‹°ë§ˆì´ì € ì •ë¦¬
        if optimizer:
            try:
                api_logger.info("ì˜µí‹°ë§ˆì´ì € ì •ë¦¬ ì¤‘...")
                if hasattr(optimizer, 'stop_monitoring'):
                    optimizer.stop_monitoring()
                if hasattr(optimizer, 'shutdown_all_workers'):
                    optimizer.shutdown_all_workers()
                api_logger.info("ì˜µí‹°ë§ˆì´ì € ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                api_logger.error(f"ì˜µí‹°ë§ˆì´ì € ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ì›Œì»¤ ì •ë¦¬
        if worker:
            try:
                api_logger.info("ì›Œì»¤ ì •ë¦¬ ì¤‘...")
                # ì›Œì»¤ ì—°ê²° ì¢…ë£Œ
                if hasattr(worker, 'connection') and worker.connection:
                    worker.connection.close()
                api_logger.info("ì›Œì»¤ ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                api_logger.error(f"ì›Œì»¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # Redis ì—°ê²° ì •ë¦¬
        try:
            api_logger.info("Redis ì—°ê²° ì •ë¦¬ ì¤‘...")
            redis_conn.close()
            api_logger.info("Redis ì—°ê²° ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            api_logger.error(f"Redis ì—°ê²° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        api_logger.info("ëª¨ë“  ì •ë¦¬ ì‘ì—… ì™„ë£Œ - ì›Œì»¤ ì¢…ë£Œ")

def start_worker_with_optimization():
    """ìµœì í™” ê¸°ëŠ¥ì´ í¬í•¨ëœ ì›Œì»¤ ì‹œì‘ - OSë³„ ëŒ€ì‘"""
    try:
        platform = "Windows" if os.name == 'nt' else "Linux/Unix"
        
        # í™˜ê²½ ì²´í¬
        api_logger.info(f"=== RQ ì›Œì»¤ í™˜ê²½ ì²´í¬ ({platform}) ===")
        api_logger.info(f"í”Œë«í¼: {os.name}")
        api_logger.info(f"Redis ì—°ê²°: {redis_host}:{redis_port}")
        
        # Redis ì—°ê²° í…ŒìŠ¤íŠ¸
        redis_conn.ping()
        api_logger.info("Redis ì—°ê²° ì„±ê³µ")
        
        # í ìƒíƒœ í™•ì¸
        queue_size = len(task_queue)
        api_logger.info(f"í˜„ì¬ í í¬ê¸°: {queue_size}")
        
        # Windows íŠ¹í™” ì²´í¬
        if os.name == 'nt':
            try:
                import psutil
                api_logger.info("psutil ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥ (í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§)")
            except ImportError:
                api_logger.warning("psutil ì—†ìŒ - ê¸°ë³¸ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬ ì‚¬ìš©")
                
            # Windows ì´ë²¤íŠ¸ ë¡œê·¸ ì²´í¬ (ì„ íƒì )
            try:
                import win32evtlog
                api_logger.info("Windows ì´ë²¤íŠ¸ ë¡œê·¸ ì‚¬ìš© ê°€ëŠ¥")
            except ImportError:
                api_logger.info("Windows ì´ë²¤íŠ¸ ë¡œê·¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ (ì„ íƒì )")
        
        # ì›Œì»¤ ì‹œì‘
        start_worker()
        
    except redis.ConnectionError as e:
        api_logger.error(f"Redis ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        raise
    except Exception as e:
        api_logger.error(f"ì›Œì»¤ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
        raise

def get_platform_info():
    """í”Œë«í¼ ì •ë³´ ì¡°íšŒ"""
    return {
        'platform': 'Windows' if os.name == 'nt' else 'Linux/Unix',
        'os_name': os.name,
        'worker_type': 'SpawnWorker' if os.name == 'nt' else 'Worker',
        'optimization_module': 'optim_rq_for_win' if os.name == 'nt' else 'optim_rq',
        'failure_handler': 'dead_letter_handle_win' if os.name == 'nt' else 'dead_letter_handle'
    }

if __name__ == '__main__':
    # í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë“œ ì„ íƒ
    mode = os.getenv('WORKER_MODE', 'optimized')
    
    # í”Œë«í¼ ì •ë³´ ì¶œë ¥
    platform_info = get_platform_info()
    api_logger.info(f"í”Œë«í¼ ì •ë³´: {platform_info}")
    
    if mode == 'optimized':
        start_worker_with_optimization()
    else:
        start_worker()